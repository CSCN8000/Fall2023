{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 2 - Probability and Statistics\n",
    "\n",
    "\n",
    "Part A  \n",
    "\n",
    "Use the **Lab2_dataset.csv** provided.\n",
    "\n",
    "- Load the dataset\n",
    "- Use the [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) function in sklearn to transform the \"text\" feature to a vector representation of a predetermined size.\n",
    "- Split the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "df = pd.read_csv('practical_labs/datasets/Lab_2/Lab2_dataset.csv')\n",
    "\n",
    "#CountVectorizer function in sklearn\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "#Splitting the dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['label_num'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training and Evaluation\n",
    "\n",
    "- Train the Sklearn SVC model on the training dataset and evaluate on the test set\n",
    "\n",
    "- Train and evaluate also on the Gaussian and Multinomial Naiive Bayes Classifiers\n",
    "\n",
    "- Compare between the performance of all models and comment on the reasons behind the differences seen between the three models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 96.52%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       742\n",
      "           1       0.93      0.95      0.94       293\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.95      0.96      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "svc_predictions = svc_model.predict(X_test)\n",
    "svc_accuracy = accuracy_score(y_test, svc_predictions)\n",
    "\n",
    "print(f\"SVC Accuracy: {svc_accuracy*100:.2f}%\")\n",
    "print(classification_report(y_test, svc_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Accuracy: 95.46%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       742\n",
      "           1       0.96      0.87      0.92       293\n",
      "\n",
      "    accuracy                           0.95      1035\n",
      "   macro avg       0.96      0.93      0.94      1035\n",
      "weighted avg       0.95      0.95      0.95      1035\n",
      "\n",
      "MultinomialNB Accuracy: 97.87%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       742\n",
      "           1       0.96      0.96      0.96       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train.toarray(), y_train)  # Convert to dense array for GaussianNB\n",
    "\n",
    "gnb_predictions = gnb_model.predict(X_test.toarray())\n",
    "gnb_accuracy = accuracy_score(y_test, gnb_predictions)\n",
    "\n",
    "print(f\"GaussianNB Accuracy: {gnb_accuracy*100:.2f}%\")\n",
    "print(classification_report(y_test, gnb_predictions))\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_train, y_train)\n",
    "\n",
    "mnb_predictions = mnb_model.predict(X_test)\n",
    "mnb_accuracy = accuracy_score(y_test, mnb_predictions)\n",
    "\n",
    "print(f\"MultinomialNB Accuracy: {mnb_accuracy*100:.2f}%\")\n",
    "print(classification_report(y_test, mnb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The Multinomial Naive Bayes, being tailored for text data, performed the best in this context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B\n",
    "\n",
    "\n",
    "Use the **AB_NYC_2019.csv** dataset for this part.\n",
    "\n",
    "Tasks\n",
    "\n",
    "- Remove outliers based on price per night for a given apartment/home.\n",
    "\n",
    "- Compare the Z-score approach and the whiskers approach in terms of who is better to remove the outliers in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (48895, 16)\n",
      "Dataset shape after Z-score outliers removal: (48507, 16)\n",
      "Dataset shape after whiskers outliers removal: (47567, 16)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\AIAlgorithm\\Fall2023\\practical_labs\\datasets\\Lab_2\\AB_NYC_2019.csv')\n",
    "\n",
    "# Calculate Z-scores for the 'price' column\n",
    "z_scores = zscore(df['price'])\n",
    "\n",
    "# Get boolean array indicating the position of outliers\n",
    "outliers_zscore = (z_scores > 3) | (z_scores < -3)\n",
    "\n",
    "# Remove outliers\n",
    "df_zscore_removed = df[~outliers_zscore]\n",
    "\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_whisker = Q1 - 3 * IQR\n",
    "upper_whisker = Q3 + 3 * IQR\n",
    "\n",
    "outliers_whiskers = (df['price'] < lower_whisker) | (df['price'] > upper_whisker)\n",
    "\n",
    "# Remove outliers\n",
    "df_whiskers_removed = df[~outliers_whiskers]\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Dataset shape after Z-score outliers removal: {df_zscore_removed.shape}\")\n",
    "print(f\"Dataset shape after whiskers outliers removal: {df_whiskers_removed.shape}\")\n",
    "\n",
    "# You can also visualize using boxplots or histograms to visually assess the removal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whiskers method removed more entries compared to the Z-score method. \n",
    "\n",
    "This suggests that there were more extreme values in the dataset that fell outside the whiskers but still within 3 standard deviations from the mean."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "cscn8010_classic_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
