{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Dev Bharatbhai Patel(8938546)</center>\n",
    "## <center>Lab-2</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><font color='Blue'>Part-A</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading lab_2_dataset.csv\n",
    "lab2_datasets = pd.read_csv(\"D:\\College\\AI_Algorith\\AI_Algorithm\\practical_labs\\datasets\\Lab_2\\Lab2_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Processing the data using 'CountVectorizer()' transform the \"text\"\n",
    "count_Vectorizer = CountVectorizer(max_features = 5000)\n",
    "X_train_v = count_Vectorizer.fit_transform(lab2_datasets['text'])\n",
    "\n",
    "# Using to.array() to convert the sparsed matrix into dense numpy array\n",
    "X_train_vectorized = X_train_v.toarray()\n",
    "\n",
    "# Spliting the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train_vectorized, lab2_datasets['label_num'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * #### Train the Sklearn SVC model on the training dataset and evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9536231884057971\n"
     ]
    }
   ],
   "source": [
    "# Training the model using SVC(Support Vector Classifier)\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "svc_model_elv = svc_model.predict(X_test)\n",
    "svc_model_con_matrix = accuracy_score(Y_test, svc_model_elv)\n",
    "\n",
    "print(svc_model_con_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Train and evaluate also on the Gaussian and Multinomial Naiive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9594202898550724\n"
     ]
    }
   ],
   "source": [
    "# Training model by Gaussian Naiive Bayes Classifier \n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluating the model \n",
    "gnb_model_elv = gnb_model.predict(X_test)\n",
    "gnb_model_con_matrix = accuracy_score(Y_test, gnb_model_elv)\n",
    "\n",
    "print(gnb_model_con_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Training model by Multinomial Naiive Bayes Classifier \n",
    "mltnb_model = MultinomialNB()\n",
    "mltnb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "mltnb_model_elv = mltnb_model.predict(X_test)\n",
    "mltnb_model_con_matrix = accuracy_score(Y_test, mltnb_model_elv)\n",
    "\n",
    "print(mltnb_model_con_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Compare between the performance of all models and comment on the reasons behind the differences seen between the three models.\n",
    "    - From the above trained model we can see that all all the models performed good, but When I was training the SVC model I don't know why but I take too much time to execute.\n",
    "    - Therefore, I used `max_feature()` to limit the data and I got the accurate result for all the models, but the Gaussian and Multinomial Naiive Bayes Classifier took less time compare to SVC.\n",
    "    \n",
    "    - So, in my opinion the Naiive Bayes Classifiers performed much better specially the `Multinomial Naiive Bayes Classifier` as we are working with textual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><font color='blue'>Part-B</font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the AB_NYC_2019.csv\n",
    "AB_NYC_data = pd.read_csv(\"D:\\College\\AI_Algorith\\AI_Algorithm\\practical_labs\\datasets\\Lab_2\\AB_NYC_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove outliers based on price per night for a given apartment/home.\n",
    "\n",
    "* Compare the Z-score approach and the whiskers approach in terms of who is better to remove the outliers in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Score before removing outliers: 48895\n",
      "Z-Scrore after removing outliers: 48507\n"
     ]
    }
   ],
   "source": [
    "# Z-score approach\n",
    "\n",
    "total_data = AB_NYC_data[\"price\"]\n",
    "mean_data = np.mean(AB_NYC_data[\"price\"])\n",
    "sd = np.std(AB_NYC_data[\"price\"])\n",
    "\n",
    "# Calculating Z-score\n",
    "z_score = (total_data - mean_data) / sd\n",
    "\n",
    "# Removing outliers\n",
    "outliers = AB_NYC_data[z_score < 3]\n",
    "\n",
    "print(\"Z-Score before removing outliers:\", len(z_score))\n",
    "print(\"Z-Scrore after removing outliers:\", len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the above outlier calculation I have use the default `3` threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whiskers: 45923\n"
     ]
    }
   ],
   "source": [
    "# Whiskers approach\n",
    "\n",
    "# Calculating the quartiles\n",
    "Q1 = AB_NYC_data['price'].quantile(0.25)\n",
    "Q3 = AB_NYC_data['price'].quantile(0.75)\n",
    "\n",
    "# Calculating the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculating the whiskers\n",
    "left_whiskers = Q1 - 1.5 * IQR\n",
    "right_whiskers = Q3 + 1.5 * IQR\n",
    "\n",
    "whiskers = AB_NYC_data[(AB_NYC_data['price'] >= left_whiskers) & (AB_NYC_data['price'] <= right_whiskers)]\n",
    "\n",
    "print(\"Whiskers:\", len(whiskers))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Well, from the result obtained it looks like whiskers approach gives more accurate result as compare to Z-score with a good amount of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "cscn8010_classic_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
