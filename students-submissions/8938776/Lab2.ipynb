{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Velon Murugathas _Lab 2_\n",
    "\n",
    "## Part A\n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 label                                               text   \n",
      "0         605   ham  Subject: enron methanol ; meter # : 988291\\nth...  \\\n",
      "1        2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
      "2        3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
      "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
      "4        2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
      "\n",
      "   label_num  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/User/Desktop/Fall2023/datasets/Lab2_dataset.csv\")                                       # Loading the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the CountVectorizer function in sklearn to transform the \"text\" feature to a vector representation of a predetermined size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()                                                                               # Using CountVectorizer to convert text to a bag-of-words representation\n",
    "\n",
    "X = vectorizer.fit_transform(df['text'])                                                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df['label'], test_size=0.2, random_state=42)          # Splitting the dataset for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation\n",
    "\n",
    "### Train the Sklearn SVC model on the training dataset and evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 0.9652173913043478\n",
      "SVC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.97      0.98       742\n",
      "        spam       0.93      0.95      0.94       293\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.95      0.96      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train Sklearn SVC model\n",
    "\n",
    "svc_model = SVC()                                           # Create an instance of the Support Vector Classifier (SVC)\n",
    "svc_model.fit(X_train, y_train)                             # Training the SVC model using the training data (X_train and y_train)\n",
    "svc_predictions = svc_model.predict(X_test)                 # Make predictions\n",
    "\n",
    "svc_accuracy = accuracy_score(y_test, svc_predictions)\n",
    "\n",
    "# Evaluating the model on test dataset\n",
    "      \n",
    "print(\"SVC Accuracy:\", svc_accuracy)\n",
    "print(\"SVC Classification Report:\")\n",
    "print(classification_report(y_test, svc_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate also on the Gaussian and Multinomial Naiive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy: 0.9545893719806763\n",
      "Gaussian Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.99      0.97       742\n",
      "        spam       0.96      0.87      0.92       293\n",
      "\n",
      "    accuracy                           0.95      1035\n",
      "   macro avg       0.96      0.93      0.94      1035\n",
      "weighted avg       0.95      0.95      0.95      1035\n",
      "\n",
      "Multinomial Naive Bayes Accuracy: 0.978743961352657\n",
      "Multinomial Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       742\n",
      "        spam       0.96      0.96      0.96       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Gaussian Naiive Bias model\n",
    "\n",
    "gaussian_nb_model = GaussianNB()                                            # Creating an instance of the Gaussian Naive Bayes classifier\n",
    "gaussian_nb_model.fit(X_train.toarray(), y_train)                           # Fit the model to training the data\n",
    "gaussian_nb_predictions = gaussian_nb_model.predict(X_test.toarray()) \n",
    "\n",
    "\n",
    "gaussian_nb_accuracy = accuracy_score(y_test, gaussian_nb_predictions)\n",
    "print(\"Gaussian Naive Bayes Accuracy:\", gaussian_nb_accuracy)\n",
    "print(\"Gaussian Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, gaussian_nb_predictions))\n",
    "\n",
    "# Training Multinomial Naiive Bias model\n",
    "\n",
    "multinomial_nb_model = MultinomialNB()                                     # Creating an instance of the Multinomial Naive Bayes classifier\n",
    "multinomial_nb_model.fit(X_train, y_train)                                 # Fit the model to training the data\n",
    "multinomial_nb_predictions = multinomial_nb_model.predict(X_test)\n",
    "\n",
    "multinomial_nb_accuracy = accuracy_score(y_test, multinomial_nb_predictions)\n",
    "print(\"Multinomial Naive Bayes Accuracy:\", multinomial_nb_accuracy)\n",
    "print(\"Multinomial Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test, multinomial_nb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare between the performance of all models and comment on the reasons behind the differences seen between the three models.\n",
    "\n",
    "* The Support Vector Classifier (SVC) achieved an accuracy of approximately 96.52% in spam detection. The SVC model demonstrated strong performance with high precision and recall values for both the \"ham\" (non-spam) and \"spam\" classes. The hyperparameter tuning and dataset characteristics, such as feature engineering could have played a role in SVC's better performance in contrast to Gaussian and Multinomial Naiive bias.\n",
    "* While the Naive Bayes models make specific assumptions about the independence of features, SVC does not rely on those. This enables SVC to handle a wider range of data distributions and relationships among features, which could explain its different and potentially better performance in certain situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B\n",
    "\n",
    "### Remove outliers based on price per night for a given apartment/home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/User/Desktop/Fall2023/datasets/AB_NYC_2019.csv\")                                                       # Loading the datasets\n",
    "\n",
    "price_column = \"price\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the Z-score approach and the whiskers approach in terms of who is better to remove the outliers in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers (Z-score approach): 388\n",
      "Number of outliers (Whiskers approach): 2972\n",
      "Size of cleaned dataset (Z-score approach): 48507\n",
      "Size of cleaned dataset (Whiskers approach): 45923\n"
     ]
    }
   ],
   "source": [
    "z_scores = np.abs(stats.zscore(df[price_column]))                                                   # Calculating Z-scores for the price column to identify outliers using the Z-score approach\n",
    "\n",
    "threshold = 3                                                                                       # Set a threshold for identifying outliers based on Z-scores (threshold corresponds to approximately three standard deviations away from the mean)\n",
    "\n",
    "outliers_zscore = df[z_scores > threshold]                                                          # Creating a DataFrame outliers_zscore containing rows with Z-scores greater than the threshold\n",
    "\n",
    "df_clean_zscore = df[z_scores <= threshold]                                                         # Creating a DataFrame df_clean_zscore containing rows without outliers Z-score approach\n",
    "\n",
    "Q1 = df[price_column].quantile(0.25)                                                                # Calculating the first quartile for price\n",
    "\n",
    "Q3 = df[price_column].quantile(0.75)                                                                # Calculating the third quartile for price\n",
    "\n",
    "IQR = Q3 - Q1                                                                                       # Calculating the interquartile range\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR                                                                        # Define lower bounds to identify outliers using the whiskers (IQR) approach\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers_whiskers = df[(df[price_column] < lower_bound) | (df[price_column] > upper_bound)]\n",
    "df_clean_whiskers = df[(df[price_column] >= lower_bound) & (df[price_column] <= upper_bound)]\n",
    "\n",
    "print(\"Number of outliers (Z-score approach):\", len(outliers_zscore))\n",
    "print(\"Number of outliers (Whiskers approach):\", len(outliers_whiskers))\n",
    "print(\"Size of cleaned dataset (Z-score approach):\", len(df_clean_zscore))\n",
    "print(\"Size of cleaned dataset (Whiskers approach):\", len(df_clean_whiskers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the Z-score approach and the whiskers approach in terms of who is better to remove the outliers in this case.\n",
    "Z-score is good at finding extreme outliers, but it can also label regular data as unusual. Whiskers are more cautious and work well with different data types without being overly sensitive to slight differences. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
