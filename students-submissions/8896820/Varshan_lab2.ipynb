{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Varshan\\Fall2023\\practical_labs\\datasets\\Lab_2\\Lab2_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text to vectors using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the models\n",
    "### Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "svc_predictions = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train.toarray(), y_train)\n",
    "gnb_predictions = gnb_model.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_train, y_train)\n",
    "mnb_predictions = mnb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Model Evaluation:\n",
      "Accuracy: 0.97\n",
      "Precision: 0.97\n",
      "Recall: 0.97\n",
      "F1-score: 0.97\n",
      "Gaussian Naive Bayes Model Evaluation:\n",
      "Accuracy: 0.95\n",
      "Precision: 0.95\n",
      "Recall: 0.95\n",
      "F1-score: 0.95\n",
      "Multinomial Naive Bayes Model Evaluation:\n",
      "Accuracy: 0.98\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1-score: 0.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate_model(predictions, model_name):\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "    print(f\"{model_name} Model Evaluation:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-score: {f1:.2f}\")\n",
    "\n",
    "evaluate_model(svc_predictions, \"SVC\")\n",
    "evaluate_model(gnb_predictions, \"Gaussian Naive Bayes\")\n",
    "evaluate_model(mnb_predictions, \"Multinomial Naive Bayes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REASONS\n",
    "\n",
    "The differences in performance can be attributed to the different assumptions and underlying algorithms of the models. SVC does not make the same assumptions as Naive Bayes models and can handle complex decision boundaries, which may explain its good performance. Multinomial Naive Bayes is well-suited for text classification tasks and performed exceptionally well in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Varshan\\Fall2023\\practical_labs\\datasets\\Lab_2\\AB_NYC_2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score approach for outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.abs(stats.zscore(data['price']))\n",
    "threshold = 3\n",
    "data_without_outliers_z = data[(z_scores < threshold)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whiskers approach for outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data['price'].quantile(0.25)\n",
    "Q3 = data['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_whisker = Q1 - 1.5 * IQR\n",
    "upper_whisker = Q3 + 1.5 * IQR\n",
    "data_without_outliers_whiskers = data[(data['price'] >= lower_whisker) & (data['price'] <= upper_whisker)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the cleaned datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (48895, 16)\n",
      "Shape after Z-score outlier removal: (48507, 16)\n",
      "Shape after whiskers outlier removal: (45923, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset shape:\", data.shape)\n",
    "print(\"Shape after Z-score outlier removal:\", data_without_outliers_z.shape)\n",
    "print(\"Shape after whiskers outlier removal:\", data_without_outliers_whiskers.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REASONS\n",
    "\n",
    "Z score removes only the extreme outliers but whisker method removes including the mild outliers, so its neccessary to use these methods for the respective needs of data analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
