{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Probability and Statistics\n",
    "\n",
    "Student Name: **Zeel Shah** (8947091)\n",
    "\n",
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading lab_2_dataset.csv\n",
    "lab2_data = pd.read_csv(\"D:/college/Fall2023/students-submissions/8947091/lab2/Lab2_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "\n",
    "count_Vectorizer = CountVectorizer(max_features = 5000)\n",
    "X = count_Vectorizer.fit_transform(lab2_data['text'])\n",
    "\n",
    "# Using to.array() to convert the sparsed matrix into dense numpy array\n",
    "X_vectorized = X.toarray()\n",
    "\n",
    "# Data Splitting into training and testing datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_vectorized, lab2_data['label_num'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "- 1st Model: SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9526570048309179\n"
     ]
    }
   ],
   "source": [
    "# Training the model using SVC\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "svc_model_pred = svc_model.predict(X_test)\n",
    "svc_model_matrix = accuracy_score(Y_test, svc_model_pred)\n",
    "\n",
    "print(svc_model_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2nd Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9690821256038648\n"
     ]
    }
   ],
   "source": [
    "# Training model by Gaussian Naiive Bayes Classifier \n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluating the model \n",
    "gnb_model_pred = gnb_model.predict(X_test)\n",
    "gnb_model_matrix = accuracy_score(Y_test, gnb_model_pred)\n",
    "\n",
    "print(gnb_model_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3rd Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Training model by Multinomial Naiive Bayes Classifier \n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "mnb_model_pred = mnb_model.predict(X_test)\n",
    "mnb_model_matrix = accuracy_score(Y_test, mnb_model_pred)\n",
    "\n",
    "print(mnb_model_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare between the performance of all models and comment on the reasons behind the differences seen between the three models.\n",
    "- After looking at the accuracy Score of all the three models, it is evident that 2nd model i.e. Gaussian Naiive Bayes Classifier is better than other two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the AB_NYC_2019.csv\n",
    "AB_NYC_data = pd.read_csv(\"D:/college/Fall2023/students-submissions/8947091/lab2/AB_NYC_2019.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Remove outliers based on price per night for a given apartment/home.\n",
    "\n",
    "-> Compare the Z-score approach and the whiskers approach in terms of who is better to remove the outliers in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before removing outliers: 48895\n",
      "Length after removing outliers: 48507\n"
     ]
    }
   ],
   "source": [
    "# Z-score approach\n",
    "\n",
    "x_data = AB_NYC_data[\"price\"]\n",
    "mean_x = np.mean(AB_NYC_data[\"price\"])\n",
    "sd_X = np.std(AB_NYC_data[\"price\"])\n",
    "\n",
    "# Calculating Z-score\n",
    "z_scores = (x_data - mean_x) / sd_X\n",
    "\n",
    "# Removing outliers\n",
    "outliers_removed = AB_NYC_data[z_scores < 3]\n",
    "\n",
    "print(\"Length before removing outliers:\", len(z_scores))\n",
    "print(\"Length after removing outliers:\", len(outliers_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whiskers Length: 45923\n"
     ]
    }
   ],
   "source": [
    "# Whiskers approach\n",
    "\n",
    "# Calculating the quartiles\n",
    "Q1 = AB_NYC_data['price'].quantile(0.25)\n",
    "Q3 = AB_NYC_data['price'].quantile(0.75)\n",
    "\n",
    "# Calculating the IQR\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculating the whiskers\n",
    "lw = Q1 - 1.5 * IQR\n",
    "rw = Q3 + 1.5 * IQR\n",
    "\n",
    "in_whiskers = AB_NYC_data[(AB_NYC_data['price'] >= lw) & (AB_NYC_data['price'] <= rw)]\n",
    "\n",
    "print(\"Whiskers Length:\", len(in_whiskers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From Observing above numbers of data It is evident that using Whiskers approach we can remove more outliers "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "cscn8010_classic_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
