{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4136, 50447)\n",
      "X_test shape: (1035, 50447)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Task 1: Load the dataset from a CSV file\n",
    "lab2_dataframe = pd.read_csv(r'C:\\Users\\91902\\Downloads\\Lab2_dataset.csv')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Task 2: Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Task 3: Fit and transform the \"text\" column of the DataFrame\n",
    "X = vectorizer.fit_transform(lab2_dataframe['text'])\n",
    "\n",
    "# Task 4: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, lab2_dataframe['label_num'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the vectorized datasets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Model Training and Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9652173913043478\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       742\n",
      "           1       0.93      0.95      0.94       293\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.95      0.96      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create an instance of the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Fit the model to your training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "report = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a.Gaussian Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Classifier Results:\n",
      "Accuracy: 0.9545893719806763\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       742\n",
      "           1       0.96      0.87      0.92       293\n",
      "\n",
      "    accuracy                           0.95      1035\n",
      "   macro avg       0.96      0.93      0.94      1035\n",
      "weighted avg       0.95      0.95      0.95      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Task 5: Create an instance of Gaussian Naive Bayes classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "# Task 6: Fit the model to your training data\n",
    "gnb_classifier.fit(X_train.toarray(), y_train)  \n",
    "\n",
    "# Task 7: Make predictions on the test data\n",
    "y_pred_gnb = gnb_classifier.predict(X_test.toarray())  # Converting X_test to array\n",
    "\n",
    "# Task 8: Calculate accuracy\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "\n",
    "# Task 9: Generate a classification report for more detailed evaluation\n",
    "report_gnb = classification_report(y_test, y_pred_gnb)\n",
    "\n",
    "# Task 10: Print the results for Gaussian Naive Bayes\n",
    "print(\"Gaussian Naive Bayes Classifier Results:\")\n",
    "print(f\"Accuracy: {accuracy_gnb}\")\n",
    "print(f\"Classification Report:\\n{report_gnb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.Multinomial Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier Results:\n",
      "Accuracy: 0.978743961352657\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       742\n",
      "           1       0.96      0.96      0.96       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Task 11: Create an instance of Multinomial Naive Bayes classifier\n",
    "mnb_classifier = MultinomialNB()\n",
    "\n",
    "# Task 12: Fit the model to your training data\n",
    "mnb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Task 13: Make predictions on the test data\n",
    "y_pred_mnb = mnb_classifier.predict(X_test)\n",
    "\n",
    "# Task 14: Calculate accuracy\n",
    "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "\n",
    "# Task 15: Generate a classification report for more detailed evaluation\n",
    "report_mnb = classification_report(y_test, y_pred_mnb)\n",
    "\n",
    "# Task 16: Print the results for Multinomial Naive Bayes\n",
    "print(\"Multinomial Naive Bayes Classifier Results:\")\n",
    "print(f\"Accuracy: {accuracy_mnb}\")\n",
    "print(f\"Classification Report:\\n{report_mnb}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9652173913043478\n",
      "Gaussian Naive Bayes Accuracy: 0.9545893719806763\n",
      "Multinomial Naive Bayes Accuracy: 0.978743961352657\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       742\n",
      "           1       0.93      0.95      0.94       293\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.95      0.96      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "SVM Confusion Matrix:\n",
      " [[720  22]\n",
      " [ 14 279]]\n",
      "Gaussian Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       742\n",
      "           1       0.96      0.87      0.92       293\n",
      "\n",
      "    accuracy                           0.95      1035\n",
      "   macro avg       0.96      0.93      0.94      1035\n",
      "weighted avg       0.95      0.95      0.95      1035\n",
      "\n",
      "Gaussian Naive Bayes Confusion Matrix:\n",
      " [[732  10]\n",
      " [ 37 256]]\n",
      "Multinomial Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       742\n",
      "           1       0.96      0.96      0.96       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Multinomial Naive Bayes Confusion Matrix:\n",
      " [[731  11]\n",
      " [ 11 282]]\n"
     ]
    }
   ],
   "source": [
    "# Task1: Calculate accuracy for each model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "\n",
    "# Task2: Print accuracy results\n",
    "print(\"SVM Accuracy:\", accuracy_svm)\n",
    "print(\"Gaussian Naive Bayes Accuracy:\", accuracy_gnb)\n",
    "print(\"Multinomial Naive Bayes Accuracy:\", accuracy_mnb)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Generate classification reports for each model\n",
    "report_svm = classification_report(y_test, y_pred_svm)\n",
    "report_gnb = classification_report(y_test, y_pred_gnb)\n",
    "report_mnb = classification_report(y_test, y_pred_mnb)\n",
    "\n",
    "# Generate confusion matrices for each model\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "cm_gnb = confusion_matrix(y_test, y_pred_gnb)\n",
    "cm_mnb = confusion_matrix(y_test, y_pred_mnb)\n",
    "\n",
    "# Task3: Print classification reports and confusion matrices\n",
    "print(\"SVM Classification Report:\\n\", report_svm)\n",
    "print(\"SVM Confusion Matrix:\\n\", cm_svm)\n",
    "\n",
    "print(\"Gaussian Naive Bayes Classification Report:\\n\", report_gnb)\n",
    "print(\"Gaussian Naive Bayes Confusion Matrix:\\n\", cm_gnb)\n",
    "\n",
    "print(\"Multinomial Naive Bayes Classification Report:\\n\", report_mnb)\n",
    "print(\"Multinomial Naive Bayes Confusion Matrix:\\n\", cm_mnb)\n",
    "\n",
    "8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffrences:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All three models perform well, with high accuracy and F1-scores.\n",
    "* Multinomial Naive Bayes outperforms the other models in terms of accuracy and recall for class 1.\n",
    "* SVM and Gaussian Naive Bayes have slightly lower recall for class 1 but still provide good overall performance.\n",
    "* The choice of the best model depends on the specific requirements of your application and the trade-offs between precision and recall.\n",
    "* Multinomial Naive Bayes may be preferred when high accuracy and balanced performance for both classes are crucial. SVM may be considered for its versatility and ability to handle\n",
    "  complex relationships in the data.\n",
    "* Overall, the Multinomial Naive Bayes model stands out in terms of accuracy and balanced performance for this dataset. However, the final model choice should consider the specific goals\n",
    "  and characteristics of your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Part B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset Size: 48895\n",
      "Z-score Approach Size: 48507\n",
      "Whiskers Approach Size: 45923\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Task 1: Load the dataset\n",
    "df = pd.read_csv('C:/Users/91902/Downloads/AB_NYC_2019.csv')\n",
    "\n",
    "# Task 2: Calculate Z-scores for 'price'\n",
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(df['price']))\n",
    "\n",
    "# Task 3: Calculate Interquartile Range (IQR) and bounds for whiskers approach\n",
    "q1 = df['price'].quantile(0.25)\n",
    "q3 = df['price'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Task 4: Remove outliers using Z-score approach\n",
    "df_zscore = df[(z_scores < 3)]  # Adjust the Z-score threshold as needed\n",
    "\n",
    "# Task 5: Remove outliers using whiskers approach\n",
    "df_whiskers = df[(df['price'] >= lower_bound) & (df['price'] <= upper_bound)]\n",
    "\n",
    "# Task 6: Compare sizes of resulting DataFrames\n",
    "print(\"Original Dataset Size:\", df.shape[0])\n",
    "print(\"Z-score Approach Size:\", df_zscore.shape[0])\n",
    "print(\"Whiskers Approach Size:\", df_whiskers.shape[0])\n",
    "\n",
    "# Task 7: Choose the final clean dataset based on analysis needs\n",
    "final_clean_dataset = df_whiskers  \n",
    "\n",
    "# Task 8: Save the final clean dataset to a new CSV file \n",
    "final_clean_dataset.to_csv('C:/Users/91902/Downloads/clean_dataset.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
