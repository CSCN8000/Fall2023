{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab-2\n",
    "Bhavesh Thadhani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 label                                               text   \n",
      "0         605   ham  Subject: enron methanol ; meter # : 988291\\nth...  \\\n",
      "1        2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
      "2        3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
      "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
      "4        2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
      "\n",
      "   label_num  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading dataset\n",
    "df = pd.read_csv('../../practical_labs/datasets/Lab_2/Lab2_dataset.csv')\n",
    "\n",
    "# Printing the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Converting text data to numerical representation\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(X)\n",
    "\n",
    "# dividing the dataset into training and testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Training SVC model\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "report_svc = classification_report(y_test, y_pred_svc)\n",
    "\n",
    "# Training Multinomial Naive Bayes model\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_train, y_train)\n",
    "y_pred_mnb = mnb_model.predict(X_test)\n",
    "accuracy_mnb = accuracy_score(y_test, y_pred_mnb)\n",
    "report_mnb = classification_report(y_test, y_pred_mnb)\n",
    "\n",
    "# Training Gaussian Naive Bayes model\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train.toarray(), y_train)\n",
    "y_pred_gnb = gnb_model.predict(X_test.toarray())\n",
    "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
    "report_gnb = classification_report(y_test, y_pred_gnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Model Accuracy: 0.9652173913043478\n",
      "SVC Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.97      0.98       742\n",
      "        spam       0.93      0.95      0.94       293\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.95      0.96      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "\n",
      "Multinomial Naive Bayes Model Accuracy: 0.978743961352657\n",
      "Multinomial Naive Bayes Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99       742\n",
      "        spam       0.96      0.96      0.96       293\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "\n",
      "Gaussian Naive Bayes Model Accuracy: 0.9545893719806763\n",
      "Gaussian Naive Bayes Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.99      0.97       742\n",
      "        spam       0.96      0.87      0.92       293\n",
      "\n",
      "    accuracy                           0.95      1035\n",
      "   macro avg       0.96      0.93      0.94      1035\n",
      "weighted avg       0.95      0.95      0.95      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing models\n",
    "print(\"SVC Model Accuracy:\", accuracy_svc)\n",
    "print(\"SVC Model Classification Report:\\n\", report_svc)\n",
    "\n",
    "print(\"\\nMultinomial Naive Bayes Model Accuracy:\", accuracy_mnb)\n",
    "print(\"Multinomial Naive Bayes Model Classification Report:\\n\", report_mnb)\n",
    "\n",
    "print(\"\\nGaussian Naive Bayes Model Accuracy:\", accuracy_gnb)\n",
    "print(\"Gaussian Naive Bayes Model Classification Report:\\n\", report_gnb)\n",
    "\n",
    "# Comment on the reasons behind the differences between models\n",
    "# Include explanations based on model assumptions and dataset characteristics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I would say the SVC model correctly identified 96.52% of spam and non-spam emails. \n",
    "The Multinomial Naive Bayes model did even better, with a 97.87% accuracy. It's like a specialized tool for understanding and spotting spam.\n",
    "The Gaussian Naive Bayes model, while still good, had a slightly lower accuracy of 95.46%. It's like a general-purpose tool that works well but not as perfectly as the specialized one.\n",
    "The reasons for these differences may include how models make assumptions, the kind of data they work with, and how they are fine-tuned. The Multinomial Naive Bayes model, designed for text, performed the best because it's tailored for this type of task.\n",
    "\n",
    "Overall, all models did well, but the specialized model was the best for this specific job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame shape: (48895, 16)\n",
      "Cleaned DataFrame shape (Z-score approach): (48507, 16)\n",
      "Cleaned DataFrame shape (Whiskers approach): (45923, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading datset\n",
    "df = pd.read_csv('../../practical_labs/datasets/Lab_2/AB_NYC_2019.csv')\n",
    "\n",
    "def remove_outliers_zscore(dataframe, column, threshold=3):\n",
    "    z_scores = np.abs((dataframe[column] - dataframe[column].mean()) / dataframe[column].std())\n",
    "    return dataframe[z_scores <= threshold]\n",
    "\n",
    "def remove_outliers_whiskers(dataframe, column):\n",
    "    Q1 = dataframe[column].quantile(0.25)\n",
    "    Q3 = dataframe[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return dataframe[(dataframe[column] >= lower_bound) & (dataframe[column] <= upper_bound)]\n",
    "\n",
    "cleaned_df_zscore = remove_outliers_zscore(df, 'price')\n",
    "\n",
    "cleaned_df_whiskers = remove_outliers_whiskers(df, 'price')\n",
    "\n",
    "print(\"Original DataFrame shape:\", df.shape)\n",
    "print(\"Cleaned DataFrame shape (Z-score approach):\", cleaned_df_zscore.shape)\n",
    "print(\"Cleaned DataFrame shape (Whiskers approach):\", cleaned_df_whiskers.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classic_ml",
   "language": "python",
   "name": "cscn8010_classic_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
