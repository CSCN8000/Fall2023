{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25978699",
   "metadata": {},
   "source": [
    "Name-Nisarg Patel\n",
    "student id-8878184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d518427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc080db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the dataset using the provided file path\n",
    "file_path = r'C:\\Users\\nisar\\Downloads\\Lab2_dataset.csv'\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6f6c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 label                                               text  \\\n",
      "0         605   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
      "1        2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
      "2        3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
      "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
      "4        2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
      "5        2949   ham  Subject: ehronline web address change\\nthis me...   \n",
      "6        2793   ham  Subject: spring savings certificate - take 30 ...   \n",
      "7        4185  spam  Subject: looking for medication ? we ` re the ...   \n",
      "8        2641   ham  Subject: noms / actual flow for 2 / 26\\nwe agr...   \n",
      "9        1870   ham  Subject: nominations for oct . 21 - 23 , 2000\\...   \n",
      "\n",
      "   label_num  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          0  \n",
      "5          0  \n",
      "6          0  \n",
      "7          1  \n",
      "8          0  \n",
      "9          0  \n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 rows of the DataFrame\n",
    "print(data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3debc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the data\n",
    "X = data['text']  # Text feature\n",
    "y = data['label']  # Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c173f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d26621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Transform the \"text\" feature using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d6d228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train and evaluate the models\n",
    "# 1 Sklearn SVC model\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train_vectorized, y_train)\n",
    "svc_predictions = svc_model.predict(X_test_vectorized)\n",
    "svc_accuracy = accuracy_score(y_test, svc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96a5346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Gaussian Naive Bayes model\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train_vectorized.toarray(), y_train)\n",
    "gnb_predictions = gnb_model.predict(X_test_vectorized.toarray())\n",
    "gnb_accuracy = accuracy_score(y_test, gnb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c21e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Multinomial Naive Bayes model\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(X_train_vectorized, y_train)\n",
    "mnb_predictions = mnb_model.predict(X_test_vectorized)\n",
    "mnb_accuracy = accuracy_score(y_test, mnb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "433d0390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Comparison:\n",
      "SVC Model Accuracy: 0.9652173913043478\n",
      "Gaussian Naive Bayes Accuracy: 0.9545893719806763\n",
      "Multinomial Naive Bayes Accuracy: 0.9719806763285024\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Compare the performance of all models\n",
    "print(\"Performance Comparison:\")\n",
    "print(\"SVC Model Accuracy:\", svc_accuracy)\n",
    "print(\"Gaussian Naive Bayes Accuracy:\", gnb_accuracy)\n",
    "print(\"Multinomial Naive Bayes Accuracy:\", mnb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de6587e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.97      0.98       742\n",
      "        spam       0.93      0.95      0.94       293\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.95      0.96      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "Gaussian Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.99      0.97       742\n",
      "        spam       0.96      0.87      0.92       293\n",
      "\n",
      "    accuracy                           0.95      1035\n",
      "   macro avg       0.96      0.93      0.94      1035\n",
      "weighted avg       0.95      0.95      0.95      1035\n",
      "\n",
      "Multinomial Naive Bayes Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.98      0.98       742\n",
      "        spam       0.96      0.95      0.95       293\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.97      0.96      0.97      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#more detailed performance metrics using classification_report\n",
    "print(\"\\nSVC Model Classification Report:\\n\", classification_report(y_test, svc_predictions))\n",
    "print(\"Gaussian Naive Bayes Classification Report:\\n\", classification_report(y_test, gnb_predictions))\n",
    "print(\"Multinomial Naive Bayes Classification Report:\\n\", classification_report(y_test, mnb_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b4202",
   "metadata": {},
   "source": [
    "#Comparison and Reasons:\n",
    "\n",
    "1.Accuracy: Gaussian Naive Bayes achieves an accuracy of 0.95, while SVC and Multinomial Naive Bayes both achieve 0.97.\n",
    "\n",
    "2.Precision: SVC correctly and accurately distinguishes non-spam emails, having the highest precision for the term \"ham.\" Gaussian Naive Bayes, however, provides the greatest accuracy for \"spam.\" It therefore has a higher likelihood of being accurate when identifying an email as spam.\n",
    "\n",
    "3.Gaussian Naive Bayes has the highest recall for the term \"ham,\" which means that it correctly recognises a large proportion of genuine non-spam emails. For \"spam,\" it has a lower recall, though. Recall for both classes is balanced in Multinomial Naive Bayes.\n",
    "\n",
    "4.The highest F1 score for \"ham,\" which balances recall and precision, belongs to SVC. F1-scores for Multinomial Naive Bayes are balanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c054eae",
   "metadata": {},
   "source": [
    "#part-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d173121d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                              name  host_id  \\\n",
      "0  2539                Clean & quiet apt home by the park     2787   \n",
      "1  2595                             Skylit Midtown Castle     2845   \n",
      "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
      "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
      "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
      "5  5099         Large Cozy 1 BR Apartment In Midtown East     7322   \n",
      "6  5121                                   BlissArtsSpace!     7356   \n",
      "7  5178                  Large Furnished Room Near B'way      8967   \n",
      "8  5203                Cozy Clean Guest Room - Family Apt     7490   \n",
      "9  5238                Cute & Cozy Lower East Side 1 bdrm     7549   \n",
      "\n",
      "     host_name neighbourhood_group       neighbourhood  latitude  longitude  \\\n",
      "0         John            Brooklyn          Kensington  40.64749  -73.97237   \n",
      "1     Jennifer           Manhattan             Midtown  40.75362  -73.98377   \n",
      "2    Elisabeth           Manhattan              Harlem  40.80902  -73.94190   \n",
      "3  LisaRoxanne            Brooklyn        Clinton Hill  40.68514  -73.95976   \n",
      "4        Laura           Manhattan         East Harlem  40.79851  -73.94399   \n",
      "5        Chris           Manhattan         Murray Hill  40.74767  -73.97500   \n",
      "6        Garon            Brooklyn  Bedford-Stuyvesant  40.68688  -73.95596   \n",
      "7     Shunichi           Manhattan      Hell's Kitchen  40.76489  -73.98493   \n",
      "8    MaryEllen           Manhattan     Upper West Side  40.80178  -73.96723   \n",
      "9          Ben           Manhattan           Chinatown  40.71344  -73.99037   \n",
      "\n",
      "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
      "0     Private room    149               1                  9  2018-10-19   \n",
      "1  Entire home/apt    225               1                 45  2019-05-21   \n",
      "2     Private room    150               3                  0         NaN   \n",
      "3  Entire home/apt     89               1                270  2019-07-05   \n",
      "4  Entire home/apt     80              10                  9  2018-11-19   \n",
      "5  Entire home/apt    200               3                 74  2019-06-22   \n",
      "6     Private room     60              45                 49  2017-10-05   \n",
      "7     Private room     79               2                430  2019-06-24   \n",
      "8     Private room     79               2                118  2017-07-21   \n",
      "9  Entire home/apt    150               1                160  2019-06-09   \n",
      "\n",
      "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
      "0               0.21                               6               365  \n",
      "1               0.38                               2               355  \n",
      "2                NaN                               1               365  \n",
      "3               4.64                               1               194  \n",
      "4               0.10                               1                 0  \n",
      "5               0.59                               1               129  \n",
      "6               0.40                               1                 0  \n",
      "7               3.47                               1               220  \n",
      "8               0.99                               1                 0  \n",
      "9               1.33                               4               188  \n",
      "count    48895.000000\n",
      "mean       152.720687\n",
      "std        240.154170\n",
      "min          0.000000\n",
      "25%         69.000000\n",
      "50%        106.000000\n",
      "75%        175.000000\n",
      "max      10000.000000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r'C:\\Users\\nisar\\Downloads\\AB_NYC_2019.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Print the first 10 rows of the DataFrame\n",
    "print(df.head(10))\n",
    "\n",
    "# Display basic statistics of the 'price' column\n",
    "print(df['price'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86c3c17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = stats.zscore(df['price'])\n",
    "\n",
    "# Define a threshold for Z-scores (e.g., 3 or -3)\n",
    "threshold = 3\n",
    "\n",
    "# Remove outliers based on Z-scores\n",
    "cleaned_df_zscore = df[(z_scores < threshold) & (z_scores > -threshold)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b927cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR (Interquartile Range)\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the whiskers\n",
    "lower_whisker = Q1 - 1.5 * IQR\n",
    "upper_whisker = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers based on whiskers\n",
    "cleaned_df_whiskers = df[(df['price'] >= lower_whisker) & (df['price'] <= upper_whisker)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "851ffab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Statistics:\n",
      "count    48895.000000\n",
      "mean       152.720687\n",
      "std        240.154170\n",
      "min          0.000000\n",
      "25%         69.000000\n",
      "50%        106.000000\n",
      "75%        175.000000\n",
      "max      10000.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Statistics after Z-score Outlier Removal:\n",
      "count    48507.000000\n",
      "mean       138.746903\n",
      "std        107.558233\n",
      "min          0.000000\n",
      "25%         69.000000\n",
      "50%        105.000000\n",
      "75%        175.000000\n",
      "max        860.000000\n",
      "Name: price, dtype: float64\n",
      "\n",
      "Statistics after Whiskers (IQR) Outlier Removal:\n",
      "count    45923.000000\n",
      "mean       119.970320\n",
      "std         68.150148\n",
      "min          0.000000\n",
      "25%         65.000000\n",
      "50%        100.000000\n",
      "75%        159.000000\n",
      "max        334.000000\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compare the statistics of the 'price' column in the original dataset and cleaned datasets\n",
    "print(\"Original Data Statistics:\")\n",
    "print(df['price'].describe())\n",
    "\n",
    "print(\"\\nStatistics after Z-score Outlier Removal:\")\n",
    "print(cleaned_df_zscore['price'].describe())\n",
    "\n",
    "print(\"\\nStatistics after Whiskers (IQR) Outlier Removal:\")\n",
    "print(cleaned_df_whiskers['price'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b373499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
